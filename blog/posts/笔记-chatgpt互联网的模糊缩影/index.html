<!doctype html><html lang=zh dir=auto><head><script src="/blog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=blog/livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[笔记] ChatGPT：互联网的模糊缩影 | Bit by Bit</title>
<meta name=keywords content="LLM,幻觉,概率,抽象能力"><meta name=description content="JPEG 有损压缩只能作为辅助理解 LLM 某些特性的类比，而不能作为其工作原理的解释；LLM 一本正经的胡说八道到底是怎么发生的；LLM 为什么算术都做不好"><meta name=author content="ViiTetrix"><link rel=canonical href=http://localhost:1313/blog/posts/%E7%AC%94%E8%AE%B0-chatgpt%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%A8%A1%E7%B3%8A%E7%BC%A9%E5%BD%B1/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/blog/logo/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/blog/logo/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/blog/logo/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/blog/logo/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/blog/logo/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=http://localhost:1313/blog/posts/%E7%AC%94%E8%AE%B0-chatgpt%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%A8%A1%E7%B3%8A%E7%BC%A9%E5%BD%B1/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/jetbrains-mono@1.0.6/css/jetbrains-mono.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/misans@4.0.0/lib/Normal/MiSans-Regular.min.css><link rel=stylesheet href=//unpkg.com/heti/umd/heti.min.css><style>body{font-family:misans regular,sans-serif!important}.heti{font-family:misans regular,sans-serif!important}.heti code,.heti pre{font-family:jetbrains mono,misans regular,sans-serif!important}.heti{--heti-font-family:"MiSans Regular", sans-serif;--heti-font-family-code:"JetBrains Mono", "MiSans Regular", sans-serif;--heti-font-family-quote:"MiSans Regular", sans-serif;--heti-font-family-title:"MiSans Regular", sans-serif}.heti h1,.heti h2,.heti h3,.heti h4,.heti h5,.heti h6,.heti p{margin-bottom:1em}</style><meta property="og:url" content="http://localhost:1313/blog/posts/%E7%AC%94%E8%AE%B0-chatgpt%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%A8%A1%E7%B3%8A%E7%BC%A9%E5%BD%B1/"><meta property="og:site_name" content="Bit by Bit"><meta property="og:title" content="[笔记] ChatGPT：互联网的模糊缩影"><meta property="og:description" content="JPEG 有损压缩只能作为辅助理解 LLM 某些特性的类比，而不能作为其工作原理的解释；LLM 一本正经的胡说八道到底是怎么发生的；LLM 为什么算术都做不好"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-06T15:07:34+08:00"><meta property="article:modified_time" content="2025-01-06T15:07:34+08:00"><meta property="article:tag" content="LLM"><meta property="article:tag" content="幻觉"><meta property="article:tag" content="概率"><meta property="article:tag" content="抽象能力"><meta name=twitter:card content="summary"><meta name=twitter:title content="[笔记] ChatGPT：互联网的模糊缩影"><meta name=twitter:description content="JPEG 有损压缩只能作为辅助理解 LLM 某些特性的类比，而不能作为其工作原理的解释；LLM 一本正经的胡说八道到底是怎么发生的；LLM 为什么算术都做不好"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"文章","item":"http://localhost:1313/blog/posts/"},{"@type":"ListItem","position":2,"name":"[笔记] ChatGPT：互联网的模糊缩影","item":"http://localhost:1313/blog/posts/%E7%AC%94%E8%AE%B0-chatgpt%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%A8%A1%E7%B3%8A%E7%BC%A9%E5%BD%B1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[笔记] ChatGPT：互联网的模糊缩影","name":"[笔记] ChatGPT：互联网的模糊缩影","description":"JPEG 有损压缩只能作为辅助理解 LLM 某些特性的类比，而不能作为其工作原理的解释；LLM 一本正经的胡说八道到底是怎么发生的；LLM 为什么算术都做不好","keywords":["LLM","幻觉","概率","抽象能力"],"articleBody":"译文链接：[译文] ChatGPT：互联网的模糊缩影 | Bit by Bit\n作者信息 Ted Chiang\n中文名：姜峯楠 生于 1967 年，美国科幻小说作家 星云奖、雨果奖获得者 作品： 小说集《你一生的故事》 小说集《呼吸》 短篇小说《你一生的故事》被改编为科幻电影《降临》 Ted Chiang | The New Yorker 投稿 内容简记 JPEG 是一种图像压缩格式，手机里拍的照片、网上看到的图片，很多都是 JPEG 格式的。它的特点是“有损压缩”，也就是说，为了减小文件大小，JPEG 会丢掉一些图像信息。丢掉的信息越多，图片就越模糊，文件也就越小。\nChatGPT 这样的 LLM，其实就是一个有损压缩版的互联网。它把网上的海量文本压缩成了一个模型，这个模型能生成各种看似通顺的文本，但它本质上是对原文的一种“模糊”处理,我们得到的永远只是以语法文本的形式呈现一个近似值。\n它学习的方式，和 JPEG 压缩图片有点像——它记住的不是每一个字、每一句话，而是“统计规律”。就像 JPEG 只记住了图片的“大致轮廓”，ChatGPT 记住的也只是语言的“大致模式”。\n所以，当我们问 ChatGPT 一个问题，它给你的答案，并不是从网上找到原文复制粘贴给的，而是根据它记住的“模式”，重新组织语言，给你一个“看起来差不多”的回答。就像 JPEG 给你的图片，虽然看起来和原图很像，但其实已经丢失了很多细节。\nLLM 的幻觉(hallucinations) 问题就像有损压缩的“副作用”。因为模型在“压缩”信息的时候，会根据一些统计规律来“脑补”缺失的部分，就像图像软件会根据周围的像素来“猜”一个丢失的像素一样。ChatGPT 有时候会一本正经地胡说八道，生成一些看似有道理、实则驴唇不对马嘴的文本。\nChatGPT 的算术能力离谱的差，更加证明了它并没有真正理解算术的原理，它知道进位这个概念却不知道如何运用，只是依靠记住的大量的例子之间的统计规律来给出答案。而我们学算术是学“规则”，而不是死记硬背“例子”。\nChatGPT 的“模糊”有时候看起来反而更“智能”，如果我们让 ChatGPT 直接引用原文，它看起来就像一个搜索引擎，我们反而会觉得它不够智能。而当它用自己的话把网上的信息重新“包装”一下，它就更像一个理解了内容的学生，而不是一个只会“死记硬背”的书呆子。\n“如果还有原图，那要这张模糊的 JPEG 干嘛？” ChatGPT 这类工具确实很强大，但它们也只是工具。ChatGPT 这类工具确实很强大，但它们也只是工具。真正重要的，还是我们人类的独立思考和创造力。\n拓展 JPEG 有损压缩只能作为辅助理解 LLM 某些特性的类比，而不能作为其工作原理的解释 JPEG 有损压缩类比的优点与缺点 优点： LLM 生成的文本，是对原始文本的一种“抽象”和“概括”，就像 JPEG 图片是对原始图片的一种“压缩”和“模糊”。 LLM 可能会“脑补”一些信息，就像 JPEG 图片可能会出现一些“失真”。 缺点： 无法解释 LLM 的核心机制 LLM 是如何学习语言的 LLM 是如何理解上下文的 LLM 是如何生成连贯的文本的 “完形填空”或许可以作为浅显理解大语言模型工作原理更贴切的类比 学习过程的相似性 先想想我们当年是怎么刷题的？是不是一本接一本的《五年高考三年模拟》，埋头苦干，就为了掌握那些出题的“套路”？LLM 也差不多，只不过它“刷”的是海量的文本数据，从里面学习语言的规律。如果把海量数据比作题海，那么可以说，AI的学习也是题海战术，而且不眠不休。\n核心机制的相似性 做完形填空的时候，我们是不是要根据上下文和选项，猜那个空里应该填啥？LLM 也一样，只不过它的“词库”大得惊人，每个词都有一个出现的概率。这就好比学霸做题都是选出最优解，而学渣做题时一半靠蒙，会想到“嗯，这个空填 A 的概率好像比 B 高一点”。这就有点像好模型和差模型了\nLLM 生成文本，就是一个词一个词（或者一个 token 一个 token）地“吐”出来，连起来就成了一句完整的话。这就更像是一个一个空格出现在句尾的完形填空。\n上下文理解的依赖性 做完形填空的时候，得联系上下文，才能选出最合适的那个词。如果上下文信息很少，或者很模糊，你就很难选对。LLM 也是，你给它的“提示”（prompt）越清楚，它就越能理解你的意思，生成的内容也越准确。这就像你跟暧昧对象聊天，你们之间的“背景信息”越多，就越能秒懂对方的意思。如果你突然来一句“在吗？”，估计对方心里会想：“这人又要干嘛？”\n双向信息的利用 做完形填空，不仅要看前面的句子，还要考虑后面的内容，这样才能填得更准确。 LLM 也学会了这一招，它用了一种叫做“Transformer”的架构，能够同时关注上下文的信息，这就是所谓的“注意力机制”。 这就像你在聚会上，不仅要听别人说了什么，还要观察周围人的反应，才能更好地接话。\n输出结果/质量的可比性： “完形填空”和 LLM 都在追求让一句话、一段话，甚至一篇文章，读起来“通顺”和“合理”。\nLLM 一本正经的胡说八道到底是怎么发生的 LLM 的“幻觉”，简单来说，就是 AI 一本正经地胡说八道，生成一些看似合理、实则完全不正确或与现实不符的内容。\n数据偏差：垃圾进，垃圾出 训练 LLM 需要喂给它海量的数据，就像养孩子一样，你给它吃什么，它就长成什么样。如果这些数据本身就存在偏差，比如充斥着各种谣言、偏见或者错误信息，亦或是不同来源的数据互相矛盾，LLM 是无法判断哪些数据有问题的，自然就无法进行可靠生成。\n有时候数据即使是真实的，但是数据分布不平衡也会带来问题。比如：网上关于“猫咪从高处落下也能毫发无损”的信息，远比“猫咪从高处落下会受伤”要多，LLM读多了，可能也会产生“猫咪怎么摔都不会受伤”的幻觉。热门领域信息丰富，冷门领域数据稀疏，也会造成认知偏差。所以训练数据的配比也非常重要。\n同时由于 LLM 的训练数据都有截至日期，在此之后的数据 LLM 并没有获取，它也不会自己实时更新，就会导致数据过时，与现在的认知产生冲突。\n上下文局限：能看到的只有这么多 LLM 对于文本的理解是有上下文窗口限制的，如果是长对话，那么早期提到的重要信息很可能在后续的回答中已经被“遗忘”了。这就像左耳朵进右耳朵出，只有中间脑子那么一小段距离的信息存在 LLM 的记忆中。\n抽象能力的缺失：只能模仿，无法“举一反三” 人类的学习，不仅仅是记住信息，更重要的是理解信息背后的逻辑和规律，并进行抽象和概括，将知识应用于不同的领域。但 LLM 目前还不具备这种能力。 它就像一个只会死记硬背的书呆子，虽然记住了很多公式和定理，但考试的时候还是不会做题。\n同时 LLM 并不懂得将其所接收的大量零散的知识打造成系统化的知识体系，知识还在，但失去了整体性，就会产生偏差。\n模式匹配的陷阱：看似聪明，实则机械 LLM 本质上是一个“模式匹配”机器，它擅长找出数据中的各种模式，然后根据这些模式来生成新的内容。但这也会导致一个问题：它可能会过度解读数据中的一些巧合或者虚假关联，从而产生一些不切实际的“幻觉”。\n比如 LLM 并不能发现数据模式之间到底是因果关系还是巧合.好比每次下雨前，蚂蚁都会搬家，于是就得出结论：蚂蚁搬家导致了下雨。这显然是荒谬的。\n缺乏实践验证：只会纸上谈兵 LLM 的知识来源于文本而不是实践经验，它没有办法通过实验来验证所获取的各种建设，也没办法对真实物理世界产生反馈，那么就不可能像人类一样从错误中学习和纠正。\n“涌现”：叛逆少年的出现 LLM 在训练过程中，随着参数、数据量等规模的扩大，会自发产生一些非设定的未明确训练的能力或者行为，这就是“涌现”。它也代表着一些不确定性。 想想一个孩子成长到了叛逆期，会做出一些只符合自己想法父母预料不到的事情。而 LLM 的涌现能力同样也无法预测，可能会促使模型自我“脑补”生成一些新颖但是未经证实的内容，或者在缺乏足够信息的时候却“过度自信”。\n概率游戏：没有事实，只有概率 LLM 给出答案，不是因为它“知道”什么是对什么是错，而是因为它根据自己学到的东西，计算出每个词出现的概率，然后进行选择。\n常在河边走，哪有不湿鞋。从概率的角度看，只要存在不确定性，就有可能出错。\n而只要一步出错，就会出现多米诺骨牌效应，一步错步步错，造成后续的结果整段偏离。\nLLM 为什么算术都做不好 LLM 的设计目标本来就不是做算术 LLM 被训练出来是为了理解和生成自然语言，而不是做算术运算。算术本来就不是 LLM 的强项。让 LLM 去做算术运算无异于让一个哲学家去解决数学问题，专业不对口啊。\n当然这只是次要因素。\nLLM 的工作机制是序列处理 LLM 在一般情况下对于数字的处理和文本一样，是按照位置顺序一个一个来的，比如说“123 + 456”，LLM 的处理视角是 “1” “2” “3” “+” “4” “5” “6” ，序列处理的局限性决定了 LLM 不能像人类一样整体把握数字，而将数字进行拆分本来就失去了其代表的含义，更不用说保证数字的精度了。\nLLM 的本质是概率生成 LLM 生成答案是基于概率分布的，即便进行算术运算也无法进行确定性生成，也就是说对于答案的“5” “7” “9”，LLM 每一步都是在掷骰子，每一步都可能产生误差。对于简单的数字可能有训练集囊括等 buff 加成出现大概率正确，但随着数字的增大，buff 加成消失，这种不确定性的累计必然会导致最终结果的偏差。LLM 能记住的，只是那些在训练数据中出现过的“特定”算式。\n数学问题训练数据的特点 有人可能会说，既然 LLM 将所有数学问题全部囊括在训练集中，增加 buff 可不可行？\n答案肯定是不可能。\n首先在正常互联网文本数据中，数学问题的样本本来就相对较少，尤其是复杂的数学运算出现的频率更低，这自然决定了占据小比例的数学问题无法成为 LLM 的专项。\n而增大数学问题样本比例，首当其中的就会影响训练数据配比，导致 LLM 在自然语言处理的主线任务上出现差错。更何况同一个数学问题在训练数据同可能有多种表达方式，单单一个算术就有无限数量的数据可以表现，将其全部囊括进样本是不可能实现的。\n抽象思维才是人类的王牌 既然囊括不了，那么教会 LLM 数学运算原理不行就了？这同样实现不了。\n我们知道关于数学运算的原理其实存在于训练集中，问题是 LLM 只会死记硬背，不会活学活用啊。\nLLM 对于抽象推理思维的缺乏决定了它虽然记住了原理，但是它理解不了运算背后的逻辑关系，更不要提利用原理推导了。单单数学概念中简单的进位、错位的概念都够 LLM 喝一壶的。\n所以，算术运算，计算器是比 LLM 更合适的选择，当然让 LLM 调取计算器等工具辅助就更合适不过了。\n","wordCount":"4052","inLanguage":"zh","datePublished":"2025-01-06T15:07:34+08:00","dateModified":"2025-01-06T15:07:34+08:00","author":[{"@type":"Person","name":"ViiTetrix"}],"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/blog/posts/%E7%AC%94%E8%AE%B0-chatgpt%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%A8%A1%E7%B3%8A%E7%BC%A9%E5%BD%B1/"},"publisher":{"@type":"Organization","name":"Bit by Bit","logo":{"@type":"ImageObject","url":"http://localhost:1313/blog/logo/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/blog/ accesskey=h title="Bit by Bit (Alt + H)"><img src=http://localhost:1313/blog/logo/apple-touch-icon.png alt aria-label=logo height=40>Bit by Bit</a><div class=logo-switches></div></div><ul id=menu><li><a href=http://localhost:1313/blog/ title=主页><span>主页</span></a></li><li><a href=http://localhost:1313/blog/posts title=文章><span>文章</span></a></li><li><a href=http://localhost:1313/blog/archives title=归档><span>归档</span></a></li><li><a href=http://localhost:1313/blog/categories title=分类><span>分类</span></a></li><li><a href=http://localhost:1313/blog/tags title=标签><span>标签</span></a></li><li><a href=http://localhost:1313/blog/search title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/blog/>首页</a>&nbsp;»&nbsp;<a href=http://localhost:1313/blog/posts/>文章</a></div><h1 class="post-title entry-hint-parent">[笔记] ChatGPT：互联网的模糊缩影</h1><div class=post-meta>创建: <span title='2025-01-06 15:07:34 +0800 CST'>2025-01-06</span> | 更新: 2025-01-06 | 字数: 4052字 | 时长: 9分钟 | 作者: ViiTetrix</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e4%bd%9c%e8%80%85%e4%bf%a1%e6%81%af aria-label=作者信息>作者信息</a></li><li><a href=#%e5%86%85%e5%ae%b9%e7%ae%80%e8%ae%b0 aria-label=内容简记>内容简记</a></li><li><a href=#%e6%8b%93%e5%b1%95 aria-label=拓展>拓展</a><ul><li><a href=#jpeg-%e6%9c%89%e6%8d%9f%e5%8e%8b%e7%bc%a9%e5%8f%aa%e8%83%bd%e4%bd%9c%e4%b8%ba%e8%be%85%e5%8a%a9%e7%90%86%e8%a7%a3-llm-%e6%9f%90%e4%ba%9b%e7%89%b9%e6%80%a7%e7%9a%84%e7%b1%bb%e6%af%94%e8%80%8c%e4%b8%8d%e8%83%bd%e4%bd%9c%e4%b8%ba%e5%85%b6%e5%b7%a5%e4%bd%9c%e5%8e%9f%e7%90%86%e7%9a%84%e8%a7%a3%e9%87%8a aria-label="JPEG 有损压缩只能作为辅助理解 LLM 某些特性的类比，而不能作为其工作原理的解释">JPEG 有损压缩只能作为辅助理解 LLM 某些特性的类比，而不能作为其工作原理的解释</a><ul><li><a href=#jpeg-%e6%9c%89%e6%8d%9f%e5%8e%8b%e7%bc%a9%e7%b1%bb%e6%af%94%e7%9a%84%e4%bc%98%e7%82%b9%e4%b8%8e%e7%bc%ba%e7%82%b9 aria-label="JPEG 有损压缩类比的优点与缺点">JPEG 有损压缩类比的优点与缺点</a><ul><li><a href=#%e4%bc%98%e7%82%b9 aria-label=优点：>优点：</a></li><li><a href=#%e7%bc%ba%e7%82%b9 aria-label=缺点：>缺点：</a></li></ul></li><li><a href=#%e5%ae%8c%e5%bd%a2%e5%a1%ab%e7%a9%ba%e6%88%96%e8%ae%b8%e5%8f%af%e4%bb%a5%e4%bd%9c%e4%b8%ba%e6%b5%85%e6%98%be%e7%90%86%e8%a7%a3%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e5%b7%a5%e4%bd%9c%e5%8e%9f%e7%90%86%e6%9b%b4%e8%b4%b4%e5%88%87%e7%9a%84%e7%b1%bb%e6%af%94 aria-label=“完形填空”或许可以作为浅显理解大语言模型工作原理更贴切的类比>“完形填空”或许可以作为浅显理解大语言模型工作原理更贴切的类比</a><ul><li><a href=#%e5%ad%a6%e4%b9%a0%e8%bf%87%e7%a8%8b%e7%9a%84%e7%9b%b8%e4%bc%bc%e6%80%a7 aria-label=学习过程的相似性>学习过程的相似性</a></li><li><a href=#%e6%a0%b8%e5%bf%83%e6%9c%ba%e5%88%b6%e7%9a%84%e7%9b%b8%e4%bc%bc%e6%80%a7 aria-label=核心机制的相似性>核心机制的相似性</a></li><li><a href=#%e4%b8%8a%e4%b8%8b%e6%96%87%e7%90%86%e8%a7%a3%e7%9a%84%e4%be%9d%e8%b5%96%e6%80%a7 aria-label=上下文理解的依赖性>上下文理解的依赖性</a></li><li><a href=#%e5%8f%8c%e5%90%91%e4%bf%a1%e6%81%af%e7%9a%84%e5%88%a9%e7%94%a8 aria-label=双向信息的利用>双向信息的利用</a></li><li><a href=#%e8%be%93%e5%87%ba%e7%bb%93%e6%9e%9c%e8%b4%a8%e9%87%8f%e7%9a%84%e5%8f%af%e6%af%94%e6%80%a7 aria-label=输出结果/质量的可比性：>输出结果/质量的可比性：</a></li></ul></li></ul></li><li><a href=#llm-%e4%b8%80%e6%9c%ac%e6%ad%a3%e7%bb%8f%e7%9a%84%e8%83%a1%e8%af%b4%e5%85%ab%e9%81%93%e5%88%b0%e5%ba%95%e6%98%af%e6%80%8e%e4%b9%88%e5%8f%91%e7%94%9f%e7%9a%84 aria-label="LLM 一本正经的胡说八道到底是怎么发生的">LLM 一本正经的胡说八道到底是怎么发生的</a><ul><li><a href=#%e6%95%b0%e6%8d%ae%e5%81%8f%e5%b7%ae%e5%9e%83%e5%9c%be%e8%bf%9b%e5%9e%83%e5%9c%be%e5%87%ba aria-label=数据偏差：垃圾进，垃圾出>数据偏差：垃圾进，垃圾出</a></li><li><a href=#%e4%b8%8a%e4%b8%8b%e6%96%87%e5%b1%80%e9%99%90%e8%83%bd%e7%9c%8b%e5%88%b0%e7%9a%84%e5%8f%aa%e6%9c%89%e8%bf%99%e4%b9%88%e5%a4%9a aria-label=上下文局限：能看到的只有这么多>上下文局限：能看到的只有这么多</a></li><li><a href=#%e6%8a%bd%e8%b1%a1%e8%83%bd%e5%8a%9b%e7%9a%84%e7%bc%ba%e5%a4%b1%e5%8f%aa%e8%83%bd%e6%a8%a1%e4%bb%bf%e6%97%a0%e6%b3%95%e4%b8%be%e4%b8%80%e5%8f%8d%e4%b8%89 aria-label=抽象能力的缺失：只能模仿，无法“举一反三”>抽象能力的缺失：只能模仿，无法“举一反三”</a></li><li><a href=#%e6%a8%a1%e5%bc%8f%e5%8c%b9%e9%85%8d%e7%9a%84%e9%99%b7%e9%98%b1%e7%9c%8b%e4%bc%bc%e8%81%aa%e6%98%8e%e5%ae%9e%e5%88%99%e6%9c%ba%e6%a2%b0 aria-label=模式匹配的陷阱：看似聪明，实则机械>模式匹配的陷阱：看似聪明，实则机械</a></li><li><a href=#%e7%bc%ba%e4%b9%8f%e5%ae%9e%e8%b7%b5%e9%aa%8c%e8%af%81%e5%8f%aa%e4%bc%9a%e7%ba%b8%e4%b8%8a%e8%b0%88%e5%85%b5 aria-label=缺乏实践验证：只会纸上谈兵>缺乏实践验证：只会纸上谈兵</a></li><li><a href=#%e6%b6%8c%e7%8e%b0%e5%8f%9b%e9%80%86%e5%b0%91%e5%b9%b4%e7%9a%84%e5%87%ba%e7%8e%b0 aria-label=&ldquo;涌现&rdquo;：叛逆少年的出现>&ldquo;涌现&rdquo;：叛逆少年的出现</a></li><li><a href=#%e6%a6%82%e7%8e%87%e6%b8%b8%e6%88%8f%e6%b2%a1%e6%9c%89%e4%ba%8b%e5%ae%9e%e5%8f%aa%e6%9c%89%e6%a6%82%e7%8e%87 aria-label=概率游戏：没有事实，只有概率>概率游戏：没有事实，只有概率</a></li></ul></li><li><a href=#llm-%e4%b8%ba%e4%bb%80%e4%b9%88%e7%ae%97%e6%9c%af%e9%83%bd%e5%81%9a%e4%b8%8d%e5%a5%bd aria-label="LLM 为什么算术都做不好">LLM 为什么算术都做不好</a><ul><li><a href=#llm-%e7%9a%84%e8%ae%be%e8%ae%a1%e7%9b%ae%e6%a0%87%e6%9c%ac%e6%9d%a5%e5%b0%b1%e4%b8%8d%e6%98%af%e5%81%9a%e7%ae%97%e6%9c%af aria-label="LLM 的设计目标本来就不是做算术">LLM 的设计目标本来就不是做算术</a></li><li><a href=#llm-%e7%9a%84%e5%b7%a5%e4%bd%9c%e6%9c%ba%e5%88%b6%e6%98%af%e5%ba%8f%e5%88%97%e5%a4%84%e7%90%86 aria-label="LLM 的工作机制是序列处理">LLM 的工作机制是序列处理</a></li><li><a href=#llm-%e7%9a%84%e6%9c%ac%e8%b4%a8%e6%98%af%e6%a6%82%e7%8e%87%e7%94%9f%e6%88%90 aria-label="LLM 的本质是概率生成">LLM 的本质是概率生成</a></li><li><a href=#%e6%95%b0%e5%ad%a6%e9%97%ae%e9%a2%98%e8%ae%ad%e7%bb%83%e6%95%b0%e6%8d%ae%e7%9a%84%e7%89%b9%e7%82%b9 aria-label=数学问题训练数据的特点>数学问题训练数据的特点</a></li><li><a href=#%e6%8a%bd%e8%b1%a1%e6%80%9d%e7%bb%b4%e6%89%8d%e6%98%af%e4%ba%ba%e7%b1%bb%e7%9a%84%e7%8e%8b%e7%89%8c aria-label=抽象思维才是人类的王牌>抽象思维才是人类的王牌</a></li></ul></li></ul></li></ul></div></details></div><div class="post-content heti heti--ancient"><p><strong>译文链接</strong>：<a href=https://viitetrix.github.io/posts/%E8%AF%91%E6%96%87-chatgpt%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%A8%A1%E7%B3%8A%E7%BC%A9%E5%BD%B1/>[译文] ChatGPT：互联网的模糊缩影 | Bit by Bit</a></p><hr><h2 id=作者信息>作者信息<a hidden class=anchor aria-hidden=true href=#作者信息>#</a></h2><br><p><img alt=Ted_jiang loading=lazy src=/img/20250106/Ted_Chiang.jpg></p><p><a href=https://en.wikipedia.org/wiki/Ted_Chiang>Ted Chiang</a></p><ul><li>中文名：姜峯楠</li><li>生于 1967 年，美国科幻小说作家</li><li>星云奖、雨果奖获得者</li><li>作品：<ul><li>小说集《<a href=https://book.douban.com/subject/26295448/>你一生的故事</a>》</li><li>小说集《<a href=https://book.douban.com/subject/34672176/>呼吸</a>》</li><li>短篇小说《你一生的故事》被改编为科幻电影《<a href=https://movie.douban.com/subject/21324900/>降临</a>》</li><li><a href=https://www.newyorker.com/contributors/ted-chiang>Ted Chiang | The New Yorker</a> 投稿</li></ul></li></ul><br><h2 id=内容简记>内容简记<a hidden class=anchor aria-hidden=true href=#内容简记>#</a></h2><br><p>JPEG 是一种图像压缩格式，手机里拍的照片、网上看到的图片，很多都是 JPEG 格式的。它的特点是“<strong>有损压缩</strong>”，也就是说，为了减小文件大小，<strong>JPEG</strong> 会丢掉一些图像信息。<strong>丢掉的信息越多，图片就越模糊，文件也就越小。</strong></p><p>ChatGPT 这样的 LLM，其实就是一个<strong>有损压缩版的互联网</strong>。它把网上的<strong>海量文本压缩</strong>成了一个模型，这个模型能生成各种看似通顺的文本，但它本质上是对原文的一种“模糊”处理,<strong>我们得到的永远只是以语法文本的形式呈现一个近似值</strong>。</p><p>它学习的方式，和 JPEG 压缩图片有点像——它记住的不是每一个字、每一句话，而是“<strong>统计规律</strong>”。就像 JPEG 只记住了图片的“大致轮廓”，ChatGPT 记住的也只是<strong>语言的“大致模式”。</strong></p><p>所以，当我们问 ChatGPT 一个问题，它给你的答案，并不是从网上找到原文复制粘贴给的，而是根据它记住的“模式”，重新组织语言，给你一个“<strong>看起来差不多</strong>”的回答。就像 JPEG 给你的图片，<strong>虽然看起来</strong>和原图很<strong>像</strong>，<strong>但其实已经丢失了很多细节</strong>。</p><p>LLM 的<strong>幻觉(hallucinations)</strong> 问题就像有损压缩的“副作用”。因为模型在“压缩”信息的时候，会根据一些统计规律来“脑补”缺失的部分，就像图像软件会根据周围的像素来“猜”一个丢失的像素一样。ChatGPT 有时候会一本正经地胡说八道，生成一些看似有道理、实则驴唇不对马嘴的文本。</p><p>ChatGPT 的算术能力离谱的差，更加证明了它并没有真正理解算术的原理，它知道进位这个概念却不知道如何运用，只是依靠记住的大量的例子之间的统计规律来给出答案。而我们学算术是<strong>学“规则”</strong>，而不是死记硬背“例子”。</p><p>ChatGPT 的“模糊”有时候看起来反而更“智能”，如果我们让 ChatGPT <strong>直接引用</strong>原文，它<strong>看起来就像一个搜索引擎</strong>，我们反而会觉得它不够智能。而当它用自己的话把网上的信息重新“<strong>包装</strong>”一下，它就<strong>更像</strong>一个<strong>理解了内容</strong>的学生，而不是一个只会“死记硬背”的书呆子。</p><p>“如果还有原图，那要这张模糊的 JPEG 干嘛？”
ChatGPT 这类工具确实很强大，但它们也<strong>只是工具</strong>。ChatGPT 这类工具确实很强大，但它们也只是工具。真正重要的，还是我们人类的<strong>独立思考和创造力</strong>。</p><br><h2 id=拓展>拓展<a hidden class=anchor aria-hidden=true href=#拓展>#</a></h2><br><h3 id=jpeg-有损压缩只能作为辅助理解-llm-某些特性的类比而不能作为其工作原理的解释>JPEG 有损压缩只能作为辅助理解 LLM <strong>某些特性</strong>的类比，而不能作为其工作原理的解释<a hidden class=anchor aria-hidden=true href=#jpeg-有损压缩只能作为辅助理解-llm-某些特性的类比而不能作为其工作原理的解释>#</a></h3><br><h4 id=jpeg-有损压缩类比的优点与缺点>JPEG 有损压缩类比的优点与缺点<a hidden class=anchor aria-hidden=true href=#jpeg-有损压缩类比的优点与缺点>#</a></h4><h5 id=优点>优点：<a hidden class=anchor aria-hidden=true href=#优点>#</a></h5><ul><li><strong>LLM 生成的文本，是对原始文本的一种“抽象”和“概括”</strong>，就像 JPEG 图片是对原始图片的一种“压缩”和“模糊”。</li><li><strong>LLM 可能会“脑补”一些信息</strong>，就像 JPEG 图片可能会出现一些“失真”。</li></ul><h5 id=缺点>缺点：<a hidden class=anchor aria-hidden=true href=#缺点>#</a></h5><ul><li>无法解释 LLM 的<strong>核心机制</strong><ul><li><ul><li>LLM 是如何学习语言的</li></ul></li><li>LLM 是如何理解上下文的</li><li>LLM 是如何生成连贯的文本的</li></ul></li></ul><h4 id=完形填空或许可以作为浅显理解大语言模型工作原理更贴切的类比>“<strong>完形填空</strong>”或许可以作为浅显理解大语言模型工作原理更贴切的类比<a hidden class=anchor aria-hidden=true href=#完形填空或许可以作为浅显理解大语言模型工作原理更贴切的类比>#</a></h4><h5 id=学习过程的相似性>学习过程的相似性<a hidden class=anchor aria-hidden=true href=#学习过程的相似性>#</a></h5><p>先想想我们当年是怎么刷题的？是不是一本接一本的《五年高考三年模拟》，埋头苦干，就为了掌握那些出题的“套路”？LLM 也差不多，只不过它“刷”的是海量的文本数据，从里面学习语言的规律。如果把海量数据比作题海，那么可以说，AI的学习也是题海战术，而且不眠不休。</p><h5 id=核心机制的相似性>核心机制的相似性<a hidden class=anchor aria-hidden=true href=#核心机制的相似性>#</a></h5><p>做完形填空的时候，我们是不是要根据上下文和选项，猜那个空里应该填啥？LLM 也一样，只不过它的“词库”大得惊人，每个词都有一个出现的概率。这就好比学霸做题都是选出最优解，而学渣做题时一半靠蒙，会想到“嗯，这个空填 A 的概率好像比 B 高一点”。这就有点像好模型和差模型了</p><p>LLM 生成文本，就是一个词一个词（或者一个 token 一个 token）地“吐”出来，连起来就成了一句完整的话。这就更像是一个一个空格出现在句尾的完形填空。</p><h5 id=上下文理解的依赖性>上下文理解的依赖性<a hidden class=anchor aria-hidden=true href=#上下文理解的依赖性>#</a></h5><p>做完形填空的时候，得联系上下文，才能选出最合适的那个词。如果上下文信息很少，或者很模糊，你就很难选对。LLM 也是，你给它的“提示”（prompt）越清楚，它就越能理解你的意思，生成的内容也越准确。这就像你跟暧昧对象聊天，你们之间的“背景信息”越多，就越能秒懂对方的意思。如果你突然来一句“在吗？”，估计对方心里会想：“这人又要干嘛？”</p><h5 id=双向信息的利用>双向信息的利用<a hidden class=anchor aria-hidden=true href=#双向信息的利用>#</a></h5><p>做完形填空，不仅要看前面的句子，还要考虑后面的内容，这样才能填得更准确。
LLM 也学会了这一招，它用了一种叫做“Transformer”的架构，能够同时关注上下文的信息，这就是所谓的“注意力机制”。
这就像你在聚会上，不仅要听别人说了什么，还要观察周围人的反应，才能更好地接话。</p><h5 id=输出结果质量的可比性>输出结果/质量的可比性：<a hidden class=anchor aria-hidden=true href=#输出结果质量的可比性>#</a></h5><p>“完形填空”和 LLM 都在追求让一句话、一段话，甚至一篇文章，读起来“通顺”和“合理”。</p><br><h3 id=llm-一本正经的胡说八道到底是怎么发生的>LLM 一本正经的胡说八道到底是怎么发生的<a hidden class=anchor aria-hidden=true href=#llm-一本正经的胡说八道到底是怎么发生的>#</a></h3><br><p>LLM 的“幻觉”，简单来说，就是 AI 一本正经地胡说八道，生成一些看似合理、实则完全不正确或与现实不符的内容。</p><h4 id=数据偏差垃圾进垃圾出>数据偏差：垃圾进，垃圾出<a hidden class=anchor aria-hidden=true href=#数据偏差垃圾进垃圾出>#</a></h4><p>训练 LLM 需要喂给它海量的数据，就像养孩子一样，你给它吃什么，它就长成什么样。如果这些数据本身就存在偏差，比如充斥着各种谣言、偏见或者错误信息，亦或是不同来源的数据互相矛盾，LLM 是无法判断哪些数据有问题的，自然就无法进行可靠生成。</p><p>有时候数据即使是真实的，但是数据分布不平衡也会带来问题。比如：网上关于“猫咪从高处落下也能毫发无损”的信息，远比“猫咪从高处落下会受伤”要多，LLM读多了，可能也会产生“猫咪怎么摔都不会受伤”的幻觉。热门领域信息丰富，冷门领域数据稀疏，也会造成认知偏差。所以训练数据的配比也非常重要。</p><p>同时由于 LLM 的训练数据都有截至日期，在此之后的数据 LLM 并没有获取，它也不会自己实时更新，就会导致数据过时，与现在的认知产生冲突。</p><h4 id=上下文局限能看到的只有这么多>上下文局限：能看到的只有这么多<a hidden class=anchor aria-hidden=true href=#上下文局限能看到的只有这么多>#</a></h4><p>LLM 对于文本的理解是有上下文窗口限制的，如果是长对话，那么早期提到的重要信息很可能在后续的回答中已经被“遗忘”了。这就像左耳朵进右耳朵出，只有中间脑子那么一小段距离的信息存在 LLM 的记忆中。</p><h4 id=抽象能力的缺失只能模仿无法举一反三>抽象能力的缺失：只能模仿，无法“举一反三”<a hidden class=anchor aria-hidden=true href=#抽象能力的缺失只能模仿无法举一反三>#</a></h4><p>人类的学习，不仅仅是记住信息，更重要的是理解信息背后的逻辑和规律，并进行抽象和概括，将知识应用于不同的领域。但 LLM 目前还不具备这种能力。
它就像一个只会死记硬背的书呆子，虽然记住了很多公式和定理，但考试的时候还是不会做题。</p><p>同时 LLM 并不懂得将其所接收的大量零散的知识打造成系统化的知识体系，知识还在，但失去了整体性，就会产生偏差。</p><h4 id=模式匹配的陷阱看似聪明实则机械>模式匹配的陷阱：看似聪明，实则机械<a hidden class=anchor aria-hidden=true href=#模式匹配的陷阱看似聪明实则机械>#</a></h4><p>LLM 本质上是一个“模式匹配”机器，它擅长找出数据中的各种模式，然后根据这些模式来生成新的内容。但这也会导致一个问题：它可能会<strong>过度解读</strong>数据中的一些巧合或者虚假关联，从而产生一些不切实际的“幻觉”。</p><p>比如 LLM 并不能发现数据模式之间到底是因果关系还是巧合.好比每次下雨前，蚂蚁都会搬家，于是就得出结论：蚂蚁搬家导致了下雨。这显然是荒谬的。</p><h4 id=缺乏实践验证只会纸上谈兵>缺乏实践验证：只会纸上谈兵<a hidden class=anchor aria-hidden=true href=#缺乏实践验证只会纸上谈兵>#</a></h4><p>LLM 的知识来源于文本而不是实践经验，它没有办法通过实验来验证所获取的各种建设，也没办法对真实物理世界产生反馈，那么就不可能像人类一样从错误中学习和纠正。</p><h4 id=涌现叛逆少年的出现>&ldquo;涌现&rdquo;：叛逆少年的出现<a hidden class=anchor aria-hidden=true href=#涌现叛逆少年的出现>#</a></h4><p>LLM 在训练过程中，随着参数、数据量等规模的扩大，会自发产生一些非设定的未明确训练的能力或者行为，这就是“涌现”。它也代表着一些不确定性。
想想一个孩子成长到了叛逆期，会做出一些只符合自己想法父母预料不到的事情。而 LLM 的涌现能力同样也无法预测，可能会促使模型自我“脑补”生成一些新颖但是未经证实的内容，或者在缺乏足够信息的时候却“过度自信”。</p><h4 id=概率游戏没有事实只有概率>概率游戏：没有事实，只有概率<a hidden class=anchor aria-hidden=true href=#概率游戏没有事实只有概率>#</a></h4><p>LLM 给出答案，不是因为它“知道”什么是对什么是错，而是因为它根据自己学到的东西，计算出每个词出现的概率，然后进行选择。</p><p>常在河边走，哪有不湿鞋。从概率的角度看，只要存在不确定性，就有可能出错。</p><p>而只要一步出错，就会出现多米诺骨牌效应，一步错步步错，造成后续的结果整段偏离。</p><br><h3 id=llm-为什么算术都做不好>LLM 为什么算术都做不好<a hidden class=anchor aria-hidden=true href=#llm-为什么算术都做不好>#</a></h3><br><h4 id=llm-的设计目标本来就不是做算术>LLM 的设计目标本来就不是做算术<a hidden class=anchor aria-hidden=true href=#llm-的设计目标本来就不是做算术>#</a></h4><p>LLM 被训练出来是为了理解和生成自然语言，而不是做算术运算。算术本来就不是 LLM 的强项。让 LLM 去做算术运算无异于让一个哲学家去解决数学问题，专业不对口啊。</p><p>当然这只是次要因素。</p><h4 id=llm-的工作机制是序列处理>LLM 的工作机制是序列处理<a hidden class=anchor aria-hidden=true href=#llm-的工作机制是序列处理>#</a></h4><p>LLM 在一般情况下对于数字的处理和文本一样，是按照位置顺序一个一个来的，比如说“123 + 456”，LLM 的处理视角是 “1” “2” “3” “+” “4” “5” “6” ，序列处理的局限性决定了 LLM 不能像人类一样整体把握数字，而将数字进行拆分本来就失去了其代表的含义，更不用说保证数字的精度了。</p><h4 id=llm-的本质是概率生成>LLM 的本质是概率生成<a hidden class=anchor aria-hidden=true href=#llm-的本质是概率生成>#</a></h4><p>LLM 生成答案是基于概率分布的，即便进行算术运算也无法进行确定性生成，也就是说对于答案的“5” “7” “9”，LLM 每一步都是在掷骰子，每一步都可能产生误差。对于简单的数字可能有训练集囊括等 buff 加成出现大概率正确，但随着数字的增大，buff 加成消失，这种不确定性的累计必然会导致最终结果的偏差。LLM 能记住的，只是那些在训练数据中出现过的“特定”算式。</p><h4 id=数学问题训练数据的特点>数学问题训练数据的特点<a hidden class=anchor aria-hidden=true href=#数学问题训练数据的特点>#</a></h4><p>有人可能会说，既然 LLM 将所有数学问题全部囊括在训练集中，增加 buff 可不可行？</p><p>答案肯定是不可能。</p><p>首先在正常互联网文本数据中，数学问题的样本本来就相对较少，尤其是复杂的数学运算出现的频率更低，这自然决定了占据小比例的数学问题无法成为 LLM 的专项。</p><p>而增大数学问题样本比例，首当其中的就会影响训练数据配比，导致 LLM 在自然语言处理的主线任务上出现差错。更何况同一个数学问题在训练数据同可能有多种表达方式，单单一个算术就有无限数量的数据可以表现，将其全部囊括进样本是不可能实现的。</p><h4 id=抽象思维才是人类的王牌>抽象思维才是人类的王牌<a hidden class=anchor aria-hidden=true href=#抽象思维才是人类的王牌>#</a></h4><p>既然囊括不了，那么教会 LLM 数学运算原理不行就了？这同样实现不了。</p><p>我们知道关于数学运算的原理其实存在于训练集中，问题是 LLM 只会死记硬背，不会活学活用啊。</p><p>LLM 对于抽象推理思维的缺乏决定了它虽然记住了原理，但是它理解不了运算背后的逻辑关系，更不要提利用原理推导了。单单数学概念中简单的进位、错位的概念都够 LLM 喝一壶的。</p><p>所以，算术运算，计算器是比 LLM 更合适的选择，当然让 LLM 调取计算器等工具辅助就更合适不过了。</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/blog/tags/llm/>LLM</a></li><li><a href=http://localhost:1313/blog/tags/%E5%B9%BB%E8%A7%89/>幻觉</a></li><li><a href=http://localhost:1313/blog/tags/%E6%A6%82%E7%8E%87/>概率</a></li><li><a href=http://localhost:1313/blog/tags/%E6%8A%BD%E8%B1%A1%E8%83%BD%E5%8A%9B/>抽象能力</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/blog/posts/%E8%AF%91%E6%96%87-%E7%94%9F%E6%88%90%E5%BC%8F%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%9B%A0-transformer-%E8%80%8C%E5%AD%98%E5%9C%A8/><span class=title>«</span><br><span>[译文] 生成式人工智能因 Transformer 而存在</span>
</a><a class=next href=http://localhost:1313/blog/posts/%E6%80%9D%E8%80%83-%E4%B9%A6%E7%AB%A5%E8%99%BD%E5%A5%BD%E5%B0%B1%E6%98%AF%E4%B8%8D%E8%83%BD%E6%9B%BF%E4%BD%A0%E8%BF%9B%E4%BA%AC%E8%B5%B6%E8%80%83/><span class=title>»</span><br><span>[思考] 书童虽好，就是不能替你进京赶考</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/blog/>Bit by Bit</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script src=//unpkg.com/heti/umd/heti-addon.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){const e=new Heti(".heti");e.autoSpacing()})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script src=//unpkg.com/heti/umd/heti-addon.min.js></script><script>window.addEventListener("load",function(){requestAnimationFrame(function(){const e=document.querySelectorAll(".heti");if(e.length>0){const e=new Heti(".heti");e.autoSpacing(),console.log("Heti initialized")}})})</script></body></html>