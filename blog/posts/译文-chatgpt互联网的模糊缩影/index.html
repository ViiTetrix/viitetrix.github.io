<!doctype html><html lang=zh dir=auto><head><script src="/blog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=blog/livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[译文] ChatGPT：互联网的模糊缩影 | Bit by Bit</title>
<meta name=keywords content="LLM,ChatGPT,有损压缩,幻觉"><meta name=description content="该文由 gemini-exp-126 翻译"><meta name=author content="Ted Chiang"><link rel=canonical href=http://localhost:1313/blog/posts/%E8%AF%91%E6%96%87-chatgpt%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%A8%A1%E7%B3%8A%E7%BC%A9%E5%BD%B1/><link crossorigin=anonymous href=/blog/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/blog/logo/favicon.ico><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/blog/logo/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/blog/logo/favicon-32x32.png><link rel=apple-touch-icon href=http://localhost:1313/blog/logo/apple-touch-icon.png><link rel=mask-icon href=http://localhost:1313/blog/logo/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=http://localhost:1313/blog/posts/%E8%AF%91%E6%96%87-chatgpt%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%A8%A1%E7%B3%8A%E7%BC%A9%E5%BD%B1/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/jetbrains-mono@1.0.6/css/jetbrains-mono.min.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/misans@4.0.0/lib/Normal/MiSans-Regular.min.css><link rel=stylesheet href=//unpkg.com/heti/umd/heti.min.css><style>body{font-family:misans regular,sans-serif!important}.heti{font-family:misans regular,sans-serif!important}.heti code,.heti pre{font-family:jetbrains mono,misans regular,sans-serif!important}.heti{--heti-font-family:"MiSans Regular", sans-serif;--heti-font-family-code:"JetBrains Mono", "MiSans Regular", sans-serif;--heti-font-family-quote:"MiSans Regular", sans-serif;--heti-font-family-title:"MiSans Regular", sans-serif}.heti h1,.heti h2,.heti h3,.heti h4,.heti h5,.heti h6,.heti p{margin-bottom:1em}</style><meta property="og:url" content="http://localhost:1313/blog/posts/%E8%AF%91%E6%96%87-chatgpt%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%A8%A1%E7%B3%8A%E7%BC%A9%E5%BD%B1/"><meta property="og:site_name" content="Bit by Bit"><meta property="og:title" content="[译文] ChatGPT：互联网的模糊缩影"><meta property="og:description" content="该文由 gemini-exp-126 翻译"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-01-05T16:48:59+08:00"><meta property="article:modified_time" content="2025-01-05T16:48:59+08:00"><meta property="article:tag" content="LLM"><meta property="article:tag" content="ChatGPT"><meta property="article:tag" content="有损压缩"><meta property="article:tag" content="幻觉"><meta name=twitter:card content="summary"><meta name=twitter:title content="[译文] ChatGPT：互联网的模糊缩影"><meta name=twitter:description content="该文由 gemini-exp-126 翻译"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"文章","item":"http://localhost:1313/blog/posts/"},{"@type":"ListItem","position":2,"name":"[译文] ChatGPT：互联网的模糊缩影","item":"http://localhost:1313/blog/posts/%E8%AF%91%E6%96%87-chatgpt%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%A8%A1%E7%B3%8A%E7%BC%A9%E5%BD%B1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[译文] ChatGPT：互联网的模糊缩影","name":"[译文] ChatGPT：互联网的模糊缩影","description":"该文由 gemini-exp-126 翻译","keywords":["LLM","ChatGPT","有损压缩","幻觉"],"articleBody":"原文链接：ChatGPT Is a Blurry JPEG of the Web | The New Yorker\n原文发布日期：2023 年 2 月 9 日\nOpenAI 的聊天机器人提供解释，而谷歌提供引用。我们更倾向于哪个？\n2013 年，一家德国建筑公司的员工发现他们的施乐复印机有点古怪：复印的房屋平面图与原件存在细微但重要的差异。原始平面图上，三个房间的面积分别用矩形标为：14.13、21.11 和 17.42 平方米。然而，在复印件中，三个房间的面积都标着 14.13 平方米。该公司联系了计算机科学家 David Kriesel 来调查这个匪夷所思的结果。之所以需要计算机科学家，是因为现代施乐复印机早已不用上世纪六十年代流行的物理静电复印技术，而是先将文件进行数字扫描，再打印出图像文件。再加上几乎所有数字图像文件都会为了节省空间而被压缩，谜底呼之欲出。\n文件压缩分两步：编码，将文件转换成更紧凑的格式；解码，将文件还原。如果还原的文件与原件完全一致，就是无损压缩，信息没有丢失。反之，如果还原的文件只是原件的近似版本，则是有损压缩，部分信息已丢失且无法恢复。无损压缩常用于文本文件和计算机程序，因为在这些领域，哪怕一个字符出错都可能造成灾难性后果。而在可以接受精度损失的情况下，有损压缩则常用于照片、音频和视频。多数时候，图片、歌曲或电影没有被完美还原，我们并不会察觉。只有当文件被极度压缩时，保真度的损失才会变得明显。我们会注意到所谓的压缩失真：比如极度压缩的 JPEG、MPEG 图像的模糊，或低比特率 MP3 听起来会很刺耳。\n施乐复印机使用一种叫 JBIG2 的有损压缩格式，主要用于黑白图像。为了节省空间，复印机会识别出图像中相似的区域，并只保存一份副本；解压时，它会重复使用该副本以重建图像。结果发现，复印机判定标注房间面积的数字足够相似，只需存储其中一个 “ 14.13 ” 并在打印平面图时重复使用。\n施乐复印机使用有损而非无损压缩格式，这本身不是问题。问题在于复印机悄无声息地降低了图像质量，且其压缩失真不易被察觉。如果复印机打印出的只是模糊的文本，大家自然会明白它并非原件的精确复制。而问题恰恰在于，复印机打印的数字清晰可读但却有误，这让复印件看似精确，实则不然。（2014 年，施乐发布了一个补丁来修复此问题。）\n我认为，在讨论 OpenAI 的 ChatGPT 及其他类似程序（AI 研究人员称之为大语言模型）时，有必要牢记施乐复印机的这段往事。复印机和大语言模型之间的相似性或许并不显而易见，但请思考以下场景：假设你即将永远无法访问互联网，为此，你计划将网络上的所有文本压缩保存到私有服务器。不幸的是，你的服务器只有所需空间的百分之一，如果想存储所有内容，就不能使用无损压缩算法。于是你编写了一个有损算法，该算法能识别文本中的统计规律，并将其存储为一种特殊的文件格式。由于你拥有几乎无限的计算能力，你的算法可以识别出极其细微的统计规律，从而实现 100:1 的惊人压缩比。\n现在，失去互联网访问权限似乎也不是那么可怕了，因为你已经在服务器上存储了网络上的所有信息。唯一的问题是，由于文本被高度压缩，你不能通过精确搜索来查找信息，因为你永远无法得到精确匹配，毕竟存储的并非字词本身。为了解决这个问题，你创建了一个界面，它接收提问形式的查询，并给出概括服务器上信息要旨的回答。\n我所描述的听起来很像 ChatGPT，或者说很像任何其他大语言模型。不妨把 ChatGPT 看作是网络上所有文本的一张模糊的 JPEG 图像。它保留了网络上的大部分信息，正如 JPEG 图像保留了高分辨率图像的大部分信息，但是如果你寻找的是一个精确的比特序列，你是找不到的；你得到的永远只是一个近似值。不过，由于这个近似值以语法文本的形式呈现，而这正是 ChatGPT 所擅长的，因此它通常可以接受。你看到的仍然是一张模糊的 JPEG 图像，但其模糊的方式并不会使整个图片看起来失真。\n这种类比不仅有助于理解 ChatGPT 如何通过变换措辞来重新组织网络信息，还可以解释大语言模型（如 ChatGPT）为何容易产生“幻觉”，即给出毫无意义的事实性回答。这些幻觉是压缩失真，但就像施乐复印机产生的错误标签一样，它们看似合理，只有与原件（即网络信息或我们的已有知识）比对后才能识别。这么一想，出现幻觉也就不足为奇了；如果一个压缩算法在丢弃了 99% 的原始内容后还能重建文本，那么其生成的很多内容完全是虚构的，也就在意料之中了。\n当我们意识到有损压缩算法常用的技术是“插值”时，这种类比就更说得通了——插值，就是通过查看空白两侧的内容来推测缺失的信息。当图像程序显示照片，需要重建压缩时丢失的像素时，它会查看附近的像素并计算平均值。这正是 ChatGPT 在收到指令时所做的，例如让它用《独立宣言》的风格描述在烘干机里丢了一只袜子，它会在“词汇空间”中取两个点，并生成填补其间空白的文本（“当人类历史的进程中，一个人有必要将其衣物与其配偶分离，以维护其清洁和秩序……”）。ChatGPT 极擅长这种插值，以至于人们觉得很有趣：这就像给文字而不是图片用了“模糊”工具，而且玩得不亦乐乎。\n鉴于 ChatGPT 等大语言模型常被吹捧为人工智能的前沿技术，将其比作有损文本压缩算法，听起来似乎是轻视，至少令人感到泄气。我承认这种观点有助于纠正人们将大语言模型拟人化的倾向，但这种压缩类比还有另一方面值得思考。自 2006 年起，一位名叫 Marcus Hutter 的 AI 研究员设立了一项奖金——“人类知识压缩奖”，又称“Hutter 奖”——奖励给那些能将维基百科一个特定的一千兆字节大小的快照进行无损压缩、且压缩后文件大小小于之前获奖者的人。你可能遇到过用 zip 格式压缩的文件。zip 格式能将 Hutter 设定的一千兆字节文件压缩到约三百兆字节，而最近的获奖者将其压缩到了 115 兆字节。这不仅仅是一次压缩练习。Hutter 认为，更好的文本压缩将有助于创造人类水平的人工智能，部分原因在于理解文本才能实现最大程度的压缩。\n为了说明压缩和理解之间的关系，想象你有一个文本文件，其中有一百万个加减乘除的例子。尽管任何压缩算法都能减小这个文件的大小，但要实现最大压缩比，可能需要推导出算术原理，然后编写一个计算器程序代码。使用计算器，你不仅可以完美重建这一百万个例子，还可以重建你未来可能遇到的任何其他算术题。同样的逻辑也适用于压缩维基百科的一个切片。如果压缩程序知道力等于质量乘以加速度，它就可以在压缩物理学页面时丢弃很多词语，因为它可以重建这些词语。同样，程序对供求关系了解得越多，它在压缩经济学页面时就能丢弃越多词语，以此类推。\n大语言模型识别文本中的统计规律。对网络文本的任何分析都会表明，“供应短缺”之类的短语经常出现在“价格上涨”之类的短语附近。一个结合了这种相关性的聊天机器人，在被问及供应短缺的影响时，可能会回答价格上涨。如果一个大语言模型汇集了大量经济学术语之间的相关性——多到足以对各种问题给出合理的回答——我们是否能说它真的理解了经济学理论？由于种种原因，像 ChatGPT 这样的模型没有资格获得 Hutter 奖，原因之一是它们不能精确重建原文，也就是说，它们并非无损压缩。但是，难道它们的有损压缩就没有展现出 AI 研究人员感兴趣的那种真正的理解吗？\n让我们回到算术的例子。如果你让 GPT-3（ChatGPT 基于的大语言模型）做两个数的加减法，当数字只有两位数时，它几乎总能给出正确答案。但随着数字变大，它的准确率会显著下降，到五位数时降至 10%。GPT-3 给出的大多数正确答案在网络上都找不到——例如，没有多少网页包含“245 + 821”——所以它并非简单记忆。但是，尽管消化了大量信息，它也未能推导出算术原理。仔细检查 GPT-3 的错误答案会发现，它在做算术时并没有进位。网络上当然有关于进位的解释，但 GPT-3 无法将这些解释纳入其中。GPT-3 对算术例子的统计分析使它能够生成真实算术的粗浅近似，但也仅此而已。\n既然 GPT-3 在小学水平的科目上都会失败，那我们该如何解释它有时在撰写大学水平论文时表现出色呢？尽管大语言模型经常产生幻觉，但在“清醒”时，它们似乎真的理解经济学理论等学科。也许算术是个特例，大语言模型并不擅长。那么在加减法之外的领域，文本中的统计规律是否真的对应着对现实世界的真实认知呢？\n我认为有一个更简单的解释。想象一下，如果 ChatGPT 是一种无损算法，它会是什么样子？如果是这样，它总是会从相关网页上逐字引用来回答问题。我们大概只会把它当作传统搜索引擎的略微改进版，而不会对它如此印象深刻。ChatGPT 改述而非逐字引用网络内容，这使它看起来像一个学生在用自己的话表达思想，而不是简单复述读过的内容；这造成了 ChatGPT 理解材料的假象。对人类学生来说，死记硬背并非真正学习的标志，所以 ChatGPT 不能精确引用网络内容，恰恰让我们以为它学到了什么。对于词语序列，有损压缩看起来比无损压缩更智能。\n人们已经提出了大语言模型的许多用途。将它们看作模糊的 JPEG 图像，可以帮助我们评估它们适合做什么，不适合做什么。我们不妨考虑几种场景。\n大语言模型能否取代传统搜索引擎？要让我们对它们有信心，就需要知道它们没有被灌输政治宣传和阴谋论——我们需要知道 JPEG 图像截取的是网络上的正确部分。但是，即使一个大语言模型只包含我们想要的信息，仍然存在模糊性的问题。有一种模糊性是可以接受的，那就是用不同的词语重新表述信息。还有一种模糊性是彻头彻尾的捏造，当我们需要事实时，这是不可接受的。目前尚不清楚在技术上能否做到在消除不可接受的模糊性的同时，保留可接受的模糊性，但我预计我们很快就会找到答案。\n即便可以限制大语言模型进行捏造，我们是否该用它们来生成网络内容？只有当我们的目标是重新包装网络上已有的信息时，这才说得通。有些公司专门干这个——我们通常称它们为“内容农场”。也许大语言模型的模糊性对它们有用，可以作为避免侵犯版权的一种方式。但总的来说，我认为任何对内容农场有利的事情，对搜索信息的人都是不利的。这种“信息再加工”的兴起，使得我们更难在网上找到所需内容；大语言模型生成的文本在网上发布得越多，网络本身就变得越模糊。\n关于 OpenAI 即将推出的 ChatGPT 继任者 GPT-4 的信息很少。但我将做一个预测：在收集用于训练 GPT-4 的大量文本时，OpenAI 的人会尽力排除 ChatGPT 或任何其他大语言模型生成的材料。如果真是这样，这将无意中证实大语言模型和有损压缩之间的类比是有用的。重复保存 JPEG 会产生更多的压缩失真，因为每次都会丢失更多信息。这相当于过去反复复印的数字版本，图像质量只会越来越差。\n实际上，衡量大语言模型质量的一个有用标准可能是，公司是否愿意使用其生成的文本作为新模型的训练材料。如果 ChatGPT 的输出对 GPT-4 来说不够好，我们就可以认为它对我们来说也不够好。反之，如果一个模型开始生成非常好的文本，好到可以用来训练新模型，那么这应该让我们对该文本的质量充满信心。（我怀疑这样的结果需要在构建这些模型的技术上取得重大突破。）而一旦模型生成的输出质量与其输入不相上下时，有损压缩的比喻就不再适用了。\n大语言模型能否帮助人们创作原创作品？要回答这个问题，我们需要明确这个问题的含义。有一种艺术流派被称为施乐艺术，或复印艺术，其中艺术家将复印机的独特属性用作创作工具。类似于 ChatGPT 的复印机肯定可以做到这一点，所以，从这个意义上说，答案是肯定的。但我认为没有人会声称复印机已成为艺术创作中必不可少的工具；绝大多数艺术家在他们的创作过程中不使用它们，也没有人争辩说他们在做出这种选择时会让自己处于不利地位。\n因此，让我们假设我们不是在谈论一种类似于施乐艺术的新型写作流派。鉴于这一规定，大语言模型生成的文本能否成为作家在创作原创作品（无论是小说还是非小说）时可以借鉴的有益起点呢？让大语言模型处理样板文件是否能让作家将注意力集中在真正有创意的部分？\n显然，没有人可以代表所有作家说话，但让我来论证一下，从一份模糊且非原创的文本开始，并非创作原创作品的良方。如果你是一位作家，在你写出原创作品之前，你会写很多非原创的作品。花费在那些非原创作品上的时间和精力并没有白费；相反，我认为，恰恰是这些努力让你最终得以创作出原创作品。遣词造句、调整语序，这些练习教会了你如何运用文字传情达意。让学生写论文不仅仅是一种测试他们对材料掌握程度的方法；它还为他们提供了表达自己想法的经验。如果学生们写的都是千篇一律的文章，他们就永远无法掌握创作新颖内容所需的技能。\n而且，一旦你不再是一名学生，你就可以安全地使用大语言模型提供的模板，情况并非如此。表达自己想法的挣扎并不会在你毕业后消失——它可能在你每次开始起草新作品时发生。有时，只有在写作的过程中，你才能发现自己的原创想法。有人可能会说，大语言模型的输出看起来与人类作家的初稿并没有什么不同，但是，我认为这是一种肤浅的相似性。你的初稿并非清晰表达的非原创内容，而是一个尚未成熟的原创想法，伴随着你隐约的不满，因为你意识到它与你理想中的表达之间的差距。这就是在重写过程中指导你的东西，也是你在开始使用人工智能生成的文本时所缺少的东西之一。\n写作没有什么神奇或神秘之处，但它不仅仅是将现有文档放在不可靠的复印机上并按下打印按钮。在未来，我们有可能构建一个人工智能，它能够仅根据自己对世界的经验来写出好的散文。我们实现这一目标的那一天将是重要的——但那一天远远超出了我们的预测范围。与此同时，我们有理由问，拥有一个可以改写 Web 的东西有什么用呢？如果我们永远失去了对互联网的访问权限，并且必须将副本存储在空间有限的私有服务器上，那么像 ChatGPT 这样的大语言模型可能是一个好的解决方案，假设它可以防止捏造。但我们并没有失去对互联网的访问权限。所以，当你仍然拥有原件时，一张模糊的 JPEG 图像到底有多大用处呢？♦\n","wordCount":"5415","inLanguage":"zh","datePublished":"2025-01-05T16:48:59+08:00","dateModified":"2025-01-05T16:48:59+08:00","author":[{"@type":"Person","name":"Ted Chiang"}],"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/blog/posts/%E8%AF%91%E6%96%87-chatgpt%E4%BA%92%E8%81%94%E7%BD%91%E7%9A%84%E6%A8%A1%E7%B3%8A%E7%BC%A9%E5%BD%B1/"},"publisher":{"@type":"Organization","name":"Bit by Bit","logo":{"@type":"ImageObject","url":"http://localhost:1313/blog/logo/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/blog/ accesskey=h title="Bit by Bit (Alt + H)"><img src=http://localhost:1313/blog/logo/apple-touch-icon.png alt aria-label=logo height=40>Bit by Bit</a><div class=logo-switches></div></div><ul id=menu><li><a href=http://localhost:1313/blog/ title=主页><span>主页</span></a></li><li><a href=http://localhost:1313/blog/posts title=文章><span>文章</span></a></li><li><a href=http://localhost:1313/blog/archives title=归档><span>归档</span></a></li><li><a href=http://localhost:1313/blog/categories title=分类><span>分类</span></a></li><li><a href=http://localhost:1313/blog/tags title=标签><span>标签</span></a></li><li><a href=http://localhost:1313/blog/search title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/blog/>首页</a>&nbsp;»&nbsp;<a href=http://localhost:1313/blog/posts/>文章</a></div><h1 class="post-title entry-hint-parent">[译文] ChatGPT：互联网的模糊缩影</h1><div class=post-description>该文由 gemini-exp-126 翻译</div><div class=post-meta>创建: <span title='2025-01-05 16:48:59 +0800 CST'>2025-01-05</span> | 更新: 2025-01-05 | 字数: 5415字 | 时长: 11分钟 | 作者: Ted Chiang</div></header><div class="post-content heti heti--ancient"><p><strong>原文链接</strong>：<a href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web?fbclid=IwAR2KNFBJOpJYOZA433GiwEQmpBjwmYXMHwtoIbGjUf_WheI7WkZl2GbucW8">ChatGPT Is a Blurry JPEG of the Web | The New Yorker</a></p><p><strong>原文发布日期</strong>：2023 年 2 月 9 日</p><hr><p>OpenAI 的聊天机器人提供解释，而谷歌提供引用。我们更倾向于哪个？</p><video width=640 height=360 autoplay loop>
<source src=https://media.newyorker.com/clips/63e3dabdbe5bf9d9d559c90d/master/pass/Chiang_final.mp4 type=video/mp4></video><p>2013 年，一家德国建筑公司的员工发现他们的施乐复印机有点古怪：复印的房屋平面图与原件存在细微但重要的差异。原始平面图上，三个房间的面积分别用矩形标为：14.13、21.11 和 17.42 平方米。然而，在复印件中，三个房间的面积都标着 14.13 平方米。该公司联系了计算机科学家 David Kriesel 来调查这个匪夷所思的结果。之所以需要计算机科学家，是因为现代施乐复印机早已不用上世纪六十年代流行的物理静电复印技术，而是先将文件进行数字扫描，再打印出图像文件。再加上几乎所有数字图像文件都会为了节省空间而被压缩，谜底呼之欲出。</p><p>文件压缩分两步：编码，将文件转换成更紧凑的格式；解码，将文件还原。如果还原的文件与原件完全一致，就是无损压缩，信息没有丢失。反之，如果还原的文件只是原件的近似版本，则是有损压缩，部分信息已丢失且无法恢复。无损压缩常用于文本文件和计算机程序，因为在这些领域，哪怕一个字符出错都可能造成灾难性后果。而在可以接受精度损失的情况下，有损压缩则常用于照片、音频和视频。多数时候，图片、歌曲或电影没有被完美还原，我们并不会察觉。只有当文件被极度压缩时，保真度的损失才会变得明显。我们会注意到所谓的压缩失真：比如极度压缩的 JPEG、MPEG 图像的模糊，或低比特率 MP3 听起来会很刺耳。</p><p>施乐复印机使用一种叫 JBIG2 的有损压缩格式，主要用于黑白图像。为了节省空间，复印机会识别出图像中相似的区域，并只保存一份副本；解压时，它会重复使用该副本以重建图像。结果发现，复印机判定标注房间面积的数字足够相似，只需存储其中一个 “ 14.13 ” 并在打印平面图时重复使用。</p><p>施乐复印机使用有损而非无损压缩格式，这本身不是问题。问题在于复印机悄无声息地降低了图像质量，且其压缩失真不易被察觉。如果复印机打印出的只是模糊的文本，大家自然会明白它并非原件的精确复制。而问题恰恰在于，复印机打印的数字清晰可读但却有误，这让复印件看似精确，实则不然。（2014 年，施乐发布了一个补丁来修复此问题。）</p><p>我认为，在讨论 OpenAI 的 ChatGPT 及其他类似程序（AI 研究人员称之为大语言模型）时，有必要牢记施乐复印机的这段往事。复印机和大语言模型之间的相似性或许并不显而易见，但请思考以下场景：假设你即将永远无法访问互联网，为此，你计划将网络上的所有文本压缩保存到私有服务器。不幸的是，你的服务器只有所需空间的百分之一，如果想存储所有内容，就不能使用无损压缩算法。于是你编写了一个有损算法，该算法能识别文本中的统计规律，并将其存储为一种特殊的文件格式。由于你拥有几乎无限的计算能力，你的算法可以识别出极其细微的统计规律，从而实现 100:1 的惊人压缩比。</p><p>现在，失去互联网访问权限似乎也不是那么可怕了，因为你已经在服务器上存储了网络上的所有信息。唯一的问题是，由于文本被高度压缩，你不能通过精确搜索来查找信息，因为你永远无法得到精确匹配，毕竟存储的并非字词本身。为了解决这个问题，你创建了一个界面，它接收提问形式的查询，并给出概括服务器上信息要旨的回答。</p><p>我所描述的听起来很像 ChatGPT，或者说很像任何其他大语言模型。不妨把 ChatGPT 看作是网络上所有文本的一张模糊的 JPEG 图像。它保留了网络上的大部分信息，正如 JPEG 图像保留了高分辨率图像的大部分信息，但是如果你寻找的是一个精确的比特序列，你是找不到的；你得到的永远只是一个近似值。不过，由于这个近似值以语法文本的形式呈现，而这正是 ChatGPT 所擅长的，因此它通常可以接受。你看到的仍然是一张模糊的 JPEG 图像，但其模糊的方式并不会使整个图片看起来失真。</p><p>这种类比不仅有助于理解 ChatGPT 如何通过变换措辞来重新组织网络信息，还可以解释大语言模型（如 ChatGPT）为何容易产生“幻觉”，即给出毫无意义的事实性回答。这些幻觉是压缩失真，但就像施乐复印机产生的错误标签一样，它们看似合理，只有与原件（即网络信息或我们的已有知识）比对后才能识别。这么一想，出现幻觉也就不足为奇了；如果一个压缩算法在丢弃了 99% 的原始内容后还能重建文本，那么其生成的很多内容完全是虚构的，也就在意料之中了。</p><p>当我们意识到有损压缩算法常用的技术是“插值”时，这种类比就更说得通了——插值，就是通过查看空白两侧的内容来推测缺失的信息。当图像程序显示照片，需要重建压缩时丢失的像素时，它会查看附近的像素并计算平均值。这正是 ChatGPT 在收到指令时所做的，例如让它用《独立宣言》的风格描述在烘干机里丢了一只袜子，它会在“词汇空间”中取两个点，并生成填补其间空白的文本（“当人类历史的进程中，一个人有必要将其衣物与其配偶分离，以维护其清洁和秩序……”）。ChatGPT 极擅长这种插值，以至于人们觉得很有趣：这就像给文字而不是图片用了“模糊”工具，而且玩得不亦乐乎。</p><p>鉴于 ChatGPT 等大语言模型常被吹捧为人工智能的前沿技术，将其比作有损文本压缩算法，听起来似乎是轻视，至少令人感到泄气。我承认这种观点有助于纠正人们将大语言模型拟人化的倾向，但这种压缩类比还有另一方面值得思考。自 2006 年起，一位名叫 Marcus Hutter 的 AI 研究员设立了一项奖金——“人类知识压缩奖”，又称“Hutter 奖”——奖励给那些能将维基百科一个特定的一千兆字节大小的快照进行无损压缩、且压缩后文件大小小于之前获奖者的人。你可能遇到过用 zip 格式压缩的文件。zip 格式能将 Hutter 设定的一千兆字节文件压缩到约三百兆字节，而最近的获奖者将其压缩到了 115 兆字节。这不仅仅是一次压缩练习。Hutter 认为，更好的文本压缩将有助于创造人类水平的人工智能，部分原因在于理解文本才能实现最大程度的压缩。</p><p>为了说明压缩和理解之间的关系，想象你有一个文本文件，其中有一百万个加减乘除的例子。尽管任何压缩算法都能减小这个文件的大小，但要实现最大压缩比，可能需要推导出算术原理，然后编写一个计算器程序代码。使用计算器，你不仅可以完美重建这一百万个例子，还可以重建你未来可能遇到的任何其他算术题。同样的逻辑也适用于压缩维基百科的一个切片。如果压缩程序知道力等于质量乘以加速度，它就可以在压缩物理学页面时丢弃很多词语，因为它可以重建这些词语。同样，程序对供求关系了解得越多，它在压缩经济学页面时就能丢弃越多词语，以此类推。</p><p>大语言模型识别文本中的统计规律。对网络文本的任何分析都会表明，“供应短缺”之类的短语经常出现在“价格上涨”之类的短语附近。一个结合了这种相关性的聊天机器人，在被问及供应短缺的影响时，可能会回答价格上涨。如果一个大语言模型汇集了大量经济学术语之间的相关性——多到足以对各种问题给出合理的回答——我们是否能说它真的理解了经济学理论？由于种种原因，像 ChatGPT 这样的模型没有资格获得 Hutter 奖，原因之一是它们不能精确重建原文，也就是说，它们并非无损压缩。但是，难道它们的有损压缩就没有展现出 AI 研究人员感兴趣的那种真正的理解吗？</p><p>让我们回到算术的例子。如果你让 GPT-3（ChatGPT 基于的大语言模型）做两个数的加减法，当数字只有两位数时，它几乎总能给出正确答案。但随着数字变大，它的准确率会显著下降，到五位数时降至 10%。GPT-3 给出的大多数正确答案在网络上都找不到——例如，没有多少网页包含“245 + 821”——所以它并非简单记忆。但是，尽管消化了大量信息，它也未能推导出算术原理。仔细检查 GPT-3 的错误答案会发现，它在做算术时并没有进位。网络上当然有关于进位的解释，但 GPT-3 无法将这些解释纳入其中。GPT-3 对算术例子的统计分析使它能够生成真实算术的粗浅近似，但也仅此而已。</p><p>既然 GPT-3 在小学水平的科目上都会失败，那我们该如何解释它有时在撰写大学水平论文时表现出色呢？尽管大语言模型经常产生幻觉，但在“清醒”时，它们似乎真的理解经济学理论等学科。也许算术是个特例，大语言模型并不擅长。那么在加减法之外的领域，文本中的统计规律是否真的对应着对现实世界的真实认知呢？</p><p>我认为有一个更简单的解释。想象一下，如果 ChatGPT 是一种无损算法，它会是什么样子？如果是这样，它总是会从相关网页上逐字引用来回答问题。我们大概只会把它当作传统搜索引擎的略微改进版，而不会对它如此印象深刻。ChatGPT 改述而非逐字引用网络内容，这使它看起来像一个学生在用自己的话表达思想，而不是简单复述读过的内容；这造成了 ChatGPT 理解材料的假象。对人类学生来说，死记硬背并非真正学习的标志，所以 ChatGPT 不能精确引用网络内容，恰恰让我们以为它学到了什么。对于词语序列，有损压缩看起来比无损压缩更智能。</p><p>人们已经提出了大语言模型的许多用途。将它们看作模糊的 JPEG 图像，可以帮助我们评估它们适合做什么，不适合做什么。我们不妨考虑几种场景。</p><p>大语言模型能否取代传统搜索引擎？要让我们对它们有信心，就需要知道它们没有被灌输政治宣传和阴谋论——我们需要知道 JPEG 图像截取的是网络上的正确部分。但是，即使一个大语言模型只包含我们想要的信息，仍然存在模糊性的问题。有一种模糊性是可以接受的，那就是用不同的词语重新表述信息。还有一种模糊性是彻头彻尾的捏造，当我们需要事实时，这是不可接受的。目前尚不清楚在技术上能否做到在消除不可接受的模糊性的同时，保留可接受的模糊性，但我预计我们很快就会找到答案。</p><p>即便可以限制大语言模型进行捏造，我们是否该用它们来生成网络内容？只有当我们的目标是重新包装网络上已有的信息时，这才说得通。有些公司专门干这个——我们通常称它们为“内容农场”。也许大语言模型的模糊性对它们有用，可以作为避免侵犯版权的一种方式。但总的来说，我认为任何对内容农场有利的事情，对搜索信息的人都是不利的。这种“信息再加工”的兴起，使得我们更难在网上找到所需内容；大语言模型生成的文本在网上发布得越多，网络本身就变得越模糊。</p><p>关于 OpenAI 即将推出的 ChatGPT 继任者 GPT-4 的信息很少。但我将做一个预测：在收集用于训练 GPT-4 的大量文本时，OpenAI 的人会尽力排除 ChatGPT 或任何其他大语言模型生成的材料。如果真是这样，这将无意中证实大语言模型和有损压缩之间的类比是有用的。重复保存 JPEG 会产生更多的压缩失真，因为每次都会丢失更多信息。这相当于过去反复复印的数字版本，图像质量只会越来越差。</p><p>实际上，衡量大语言模型质量的一个有用标准可能是，公司是否愿意使用其生成的文本作为新模型的训练材料。如果 ChatGPT 的输出对 GPT-4 来说不够好，我们就可以认为它对我们来说也不够好。反之，如果一个模型开始生成非常好的文本，好到可以用来训练新模型，那么这应该让我们对该文本的质量充满信心。（我怀疑这样的结果需要在构建这些模型的技术上取得重大突破。）而一旦模型生成的输出质量与其输入不相上下时，有损压缩的比喻就不再适用了。</p><p>大语言模型能否帮助人们创作原创作品？要回答这个问题，我们需要明确这个问题的含义。有一种艺术流派被称为施乐艺术，或复印艺术，其中艺术家将复印机的独特属性用作创作工具。类似于 ChatGPT 的复印机肯定可以做到这一点，所以，从这个意义上说，答案是肯定的。但我认为没有人会声称复印机已成为艺术创作中必不可少的工具；绝大多数艺术家在他们的创作过程中不使用它们，也没有人争辩说他们在做出这种选择时会让自己处于不利地位。</p><p>因此，让我们假设我们不是在谈论一种类似于施乐艺术的新型写作流派。鉴于这一规定，大语言模型生成的文本能否成为作家在创作原创作品（无论是小说还是非小说）时可以借鉴的有益起点呢？让大语言模型处理样板文件是否能让作家将注意力集中在真正有创意的部分？</p><p>显然，没有人可以代表所有作家说话，但让我来论证一下，从一份模糊且非原创的文本开始，并非创作原创作品的良方。如果你是一位作家，在你写出原创作品之前，你会写很多非原创的作品。花费在那些非原创作品上的时间和精力并没有白费；相反，我认为，恰恰是这些努力让你最终得以创作出原创作品。遣词造句、调整语序，这些练习教会了你如何运用文字传情达意。让学生写论文不仅仅是一种测试他们对材料掌握程度的方法；它还为他们提供了表达自己想法的经验。如果学生们写的都是千篇一律的文章，他们就永远无法掌握创作新颖内容所需的技能。</p><p>而且，一旦你不再是一名学生，你就可以安全地使用大语言模型提供的模板，情况并非如此。表达自己想法的挣扎并不会在你毕业后消失——它可能在你每次开始起草新作品时发生。有时，只有在写作的过程中，你才能发现自己的原创想法。有人可能会说，大语言模型的输出看起来与人类作家的初稿并没有什么不同，但是，我认为这是一种肤浅的相似性。你的初稿并非清晰表达的非原创内容，而是一个尚未成熟的原创想法，伴随着你隐约的不满，因为你意识到它与你理想中的表达之间的差距。这就是在重写过程中指导你的东西，也是你在开始使用人工智能生成的文本时所缺少的东西之一。</p><p>写作没有什么神奇或神秘之处，但它不仅仅是将现有文档放在不可靠的复印机上并按下打印按钮。在未来，我们有可能构建一个人工智能，它能够仅根据自己对世界的经验来写出好的散文。我们实现这一目标的那一天将是重要的——但那一天远远超出了我们的预测范围。与此同时，我们有理由问，拥有一个可以改写 Web 的东西有什么用呢？如果我们永远失去了对互联网的访问权限，并且必须将副本存储在空间有限的私有服务器上，那么像 ChatGPT 这样的大语言模型可能是一个好的解决方案，假设它可以防止捏造。但我们并没有失去对互联网的访问权限。所以，当你仍然拥有原件时，一张模糊的 JPEG 图像到底有多大用处呢？♦</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://localhost:1313/blog/tags/llm/>LLM</a></li><li><a href=http://localhost:1313/blog/tags/chatgpt/>ChatGPT</a></li><li><a href=http://localhost:1313/blog/tags/%E6%9C%89%E6%8D%9F%E5%8E%8B%E7%BC%A9/>有损压缩</a></li><li><a href=http://localhost:1313/blog/tags/%E5%B9%BB%E8%A7%89/>幻觉</a></li></ul><nav class=paginav><a class=prev href=http://localhost:1313/blog/posts/%E6%80%9D%E8%80%83-%E4%B9%A6%E7%AB%A5%E8%99%BD%E5%A5%BD%E5%B0%B1%E6%98%AF%E4%B8%8D%E8%83%BD%E6%9B%BF%E4%BD%A0%E8%BF%9B%E4%BA%AC%E8%B5%B6%E8%80%83/><span class=title>«</span><br><span>[思考] 书童虽好，就是不能替你进京赶考</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/blog/>Bit by Bit</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script src=//unpkg.com/heti/umd/heti-addon.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){const e=new Heti(".heti");e.autoSpacing()})</script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script src=//unpkg.com/heti/umd/heti-addon.min.js></script><script>window.addEventListener("load",function(){requestAnimationFrame(function(){const e=document.querySelectorAll(".heti");if(e.length>0){const e=new Heti(".heti");e.autoSpacing(),console.log("Heti initialized")}})})</script></body></html>